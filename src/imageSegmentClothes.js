import { useEffect, useRef } from "react";
import { FilesetResolver, ImageSegmenter } from "@mediapipe/tasks-vision";
import { colorDistance } from "./colorutil";
// import { extractDominantColorsKMeans } from "./k-means"; // å‰Šé™¤

// Helper: confidenceMask ã‚’ Float32Array ã«å¤‰æ›ã—ã¦è¿”ã™
function maskToFloat32Array(confidenceMaskImage) {
  try {
    if (!confidenceMaskImage) {
      console.warn("maskToFloat32Array: ç„¡åŠ¹ãªå…¥åŠ›");
      return null;
    }
    if (typeof confidenceMaskImage.getAsFloat32Array === "function") {
      return confidenceMaskImage.getAsFloat32Array();
    }
    if (confidenceMaskImage.data) {
      const buffer = confidenceMaskImage.data.buffer || confidenceMaskImage.data;
      return new Float32Array(buffer);
    }
    console.warn("maskToFloat32Array: ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ‡ãƒ¼ã‚¿å½¢å¼");
  } catch (e) {
    console.error("maskToFloat32Array ã‚¨ãƒ©ãƒ¼:", e);
  }
  return null;
}

let segmenterPromise = null;
const getSegmenter = async () => {
  if (!segmenterPromise) {
    segmenterPromise = (async () => {
      console.log("ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–");
      const vision = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm"
      );
      const modelUrl =
        "https://storage.googleapis.com/mediapipe-models/image_segmenter/selfie_multiclass_256x256/float32/latest/selfie_multiclass_256x256.tflite";
      
      const videoSegmenter = await ImageSegmenter.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath: modelUrl,
          delegate: "GPU",
        },
        outputCategoryMask: false,
        outputConfidenceMasks: true,
        runningMode: "VIDEO",
      });

      const imageSegmenter = await ImageSegmenter.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath: modelUrl,
        },
        outputCategoryMask: false,
        outputConfidenceMasks: true,
        runningMode: "IMAGE",
      });

      return { videoSegmenter, imageSegmenter };
    })();
  }
  return await segmenterPromise;
};


const ImageSegmentClothes = ({ videoRef, canvasRef, maskAlpha = 0.6, freqMs = 100, confidenceThreshold = 0.5, isCapturing, setAllExtractedColors, onCaptureFinished, onProgress, rotation = 90 }) => { // rotation ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¿½åŠ 
  const videoSegmenterRef = useRef(null);
  const imageSegmenterRef = useRef(null);
  const streamRef = useRef(null);
  const captureModeRef = useRef(false);

  // Effect for initialization
  useEffect(() => {
    let mounted = true;

    const init = async () => {
      const { videoSegmenter, imageSegmenter } = await getSegmenter();
      videoSegmenterRef.current = videoSegmenter;
      imageSegmenterRef.current = imageSegmenter;

      try {
        streamRef.current = await navigator.mediaDevices.getUserMedia({ video: true });
        if (mounted && videoRef.current) {
          videoRef.current.srcObject = streamRef.current;
          await videoRef.current.play();
        }
      } catch (e) {
        console.error("Failed to get user media", e);
      }
    };
console.log("ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–")
    init();

    return () => {
      mounted = false;
      if (streamRef.current) {
        streamRef.current.getTracks().forEach((t) => t.stop());
      }
    };
  }, [videoRef]);

  // ã‚­ãƒ£ãƒ³ãƒã‚¹ã®å›è»¢è¨­å®šã‚’é©ç”¨ã™ã‚‹é–¢æ•°
  const applyCanvasRotation = (ctx, canvas, video, rotation) => {
    if (rotation === 90) {
      canvas.width = video.videoHeight;
      canvas.height = video.videoWidth;
      ctx.save();
      ctx.translate(canvas.width, 0);
      ctx.rotate(90 * Math.PI / 180);
    } else if (rotation === 180) {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx.save();
      ctx.translate(canvas.width, canvas.height);
      ctx.rotate(180 * Math.PI / 180);
    } else if (rotation === 270) {
      canvas.width = video.videoHeight;
      canvas.height = video.videoWidth;
      ctx.save();
      ctx.translate(0, canvas.height);
      ctx.rotate(270 * Math.PI / 180);
    } else {
      // å›è»¢ãªã—
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx.save();
    }
  };

  // Effect for rendering loop
  useEffect(() => {
    let lastRun = 0;
    let animationFrameId;
    let mounted = true;

    const renderLoop = async (now) => {
      if (!mounted || !videoRef.current || !canvasRef.current || !videoSegmenterRef.current) {
        if(mounted) animationFrameId = requestAnimationFrame(renderLoop);
        return;
      }
      
      const video = videoRef.current;
      if (video.ended) {
        animationFrameId = requestAnimationFrame(renderLoop);
        return;
      }
      
      // ã‚­ãƒ£ãƒ—ãƒãƒ£ãƒ¢ãƒ¼ãƒ‰ä¸­ã¯æ›´æ–°ã‚’åœæ­¢
      if (captureModeRef.current) {
        animationFrameId = requestAnimationFrame(renderLoop);
        return;
      }
      
      if (video.paused) {
        animationFrameId = requestAnimationFrame(renderLoop);
        return;
      }


      if (freqMs <= 0 || now - lastRun >= freqMs) {
        lastRun = now;
        
        try {
          // å…ƒã®å‘ãã®ã¾ã¾ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
          const res = videoSegmenterRef.current.segmentForVideo(video, now);
          const canvas = canvasRef.current;
          const ctx = canvas.getContext("2d");

          const CLOTHES_CLASS = 4;
          const clothesConfidenceMask = res.confidenceMasks && res.confidenceMasks[CLOTHES_CLASS];

          // ã‚­ãƒ£ãƒ³ãƒã‚¹ã®ã‚µã‚¤ã‚ºã‚’è¨­å®š
          if (rotation === 90 || rotation === 270) {
            canvas.width = video.videoHeight;
            canvas.height = video.videoWidth;
          } else {
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
          }
          ctx.clearRect(0, 0, canvas.width, canvas.height);
          
          // å›è»¢ã‚’é©ç”¨
          ctx.save();
          if (rotation === 90) {
            ctx.translate(canvas.width, 0);
            ctx.rotate(90 * Math.PI / 180);
          } else if (rotation === 180) {
            ctx.translate(canvas.width, canvas.height);
            ctx.rotate(180 * Math.PI / 180);
          } else if (rotation === 270) {
            ctx.translate(0, canvas.height);
            ctx.rotate(270 * Math.PI / 180);
          }

          if (clothesConfidenceMask) {
            const mw = clothesConfidenceMask.width || video.videoWidth;
            const mh = clothesConfidenceMask.height || video.videoHeight;
            const maskArray = maskToFloat32Array(clothesConfidenceMask);

            if (maskArray) {
              const tempCanvas = document.createElement("canvas");
              tempCanvas.width = video.videoWidth;
              tempCanvas.height = video.videoHeight;
              const tempCtx = tempCanvas.getContext("2d");
              tempCtx.drawImage(video, 0, 0, video.videoWidth, video.videoHeight);
              const originalImageData = tempCtx.getImageData(0, 0, video.videoWidth, video.videoHeight);
              const originalPixels = originalImageData.data;

              const out = new Uint8ClampedArray(mw * mh * 4);
              for (let i = 0, j = 0; i < maskArray.length; i++, j += 4) {
                const confidence = maskArray[i];
                if (confidence > confidenceThreshold) {
                  out[j] = originalPixels[j];
                  out[j + 1] = originalPixels[j + 1];
                  out[j + 2] = originalPixels[j + 2];
                  out[j + 3] = 255;
                } else {
                  const darkenFactor = 0.3;
                  out[j] = originalPixels[j] * darkenFactor;
                  out[j + 1] = originalPixels[j + 1] * darkenFactor;
                  out[j + 2] = originalPixels[j + 2] * darkenFactor;
                  out[j + 3] = Math.floor(maskAlpha * 255);
                }
              }
              const imageData = new ImageData(out, mw, mh);
              ctx.drawImage(await createImageBitmap(imageData), 0, 0, video.videoWidth, video.videoHeight);
            } else {
              ctx.drawImage(video, 0, 0, video.videoWidth, video.videoHeight);
            }
          } else {
            ctx.drawImage(video, 0, 0, video.videoWidth, video.videoHeight);
          }
          
          // å›è»¢çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
          ctx.restore();
        } catch (err) {
          console.error("segmentForVideo error:", err);
        }
      }
      animationFrameId = requestAnimationFrame(renderLoop);
    };

    const video = videoRef.current;
    const handlePlaying = () => {
        cancelAnimationFrame(animationFrameId);
        animationFrameId = requestAnimationFrame(renderLoop);
    }
    if (video) {
      video.addEventListener("playing", handlePlaying);
    }
    
    animationFrameId = requestAnimationFrame(renderLoop);

    return () => {
      mounted = false;
      if (video) {
        video.removeEventListener("playing", handlePlaying);
      }
      cancelAnimationFrame(animationFrameId);
    };
  }, [videoRef, canvasRef, maskAlpha, freqMs, confidenceThreshold, rotation]);

 useEffect(() => {
  const process = async () => {
    if (
      isCapturing &&
      streamRef.current &&
      videoRef.current &&
      canvasRef.current &&
      videoSegmenterRef.current &&
      imageSegmenterRef.current
    ) {
      captureModeRef.current = true;
      // ã‚«ãƒ¡ãƒ©ã¯åœæ­¢ã›ãšã€videoã®ã¿ä¸€æ™‚åœæ­¢
      const video = videoRef.current;
      video.pause(); // ãƒ“ãƒ‡ã‚ªã‚’ä¸€æ™‚åœæ­¢

      const canvas = canvasRef.current;
      const ctx = canvas.getContext("2d");

      // å…ƒã®å‘ãã®ã¾ã¾ImageDataã‚’å–å¾—
      const tempCanvas = document.createElement("canvas");
      tempCanvas.width = video.videoWidth;
      tempCanvas.height = video.videoHeight;
      const tempCtx = tempCanvas.getContext("2d");
      tempCtx.drawImage(video, 0, 0, video.videoWidth, video.videoHeight);
      const originalImageData = tempCtx.getImageData(0, 0, video.videoWidth, video.videoHeight);

      // å›è»¢æ¸ˆã¿ã®ç”»åƒã§ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
      const res = imageSegmenterRef.current.segment(originalImageData);

      // ã‚­ãƒ£ãƒ³ãƒã‚¹ã®ã‚µã‚¤ã‚ºã‚’è¨­å®š
      if (rotation === 90 || rotation === 270) {
        canvas.width = video.videoHeight;
        canvas.height = video.videoWidth;
      } else {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
      }
      ctx.drawImage(tempCanvas, 0, 0);

      const CLOTHES_CLASS = 4;
      const clothesConfidenceMask = res.confidenceMasks && res.confidenceMasks[CLOTHES_CLASS];

      if (clothesConfidenceMask) {
        const mw = clothesConfidenceMask.width || video.videoWidth;
        const mh = clothesConfidenceMask.height || video.videoHeight;
        const maskArray = maskToFloat32Array(clothesConfidenceMask);
        let localColors = [];

        if (maskArray) {
          // ğŸš€ é«˜é€ŸåŒ–ï¼šãƒ©ãƒ³ãƒ€ãƒ 100pxãšã¤æŠ½å‡ºã—ã¦éƒ½åº¦æ›´æ–°
         const processMask = () => new Promise((resolve) => {
  const totalPixels = maskArray.length;
  const sampleCount = 20000; // 2000ãƒ”ã‚¯ã‚»ãƒ«ã ã‘ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆç´„0.1%ï¼‰
  let sampled = 0;

  // äº‹å‰ã«ãƒ©ãƒ³ãƒ€ãƒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ã¾ã¨ã‚ã¦ä½œã‚‹ï¼ˆé«˜é€Ÿï¼‰
  const indices = new Uint32Array(sampleCount);
  for (let i = 0; i < sampleCount; i++) {
    indices[i] = Math.floor(Math.random() * totalPixels);
  }

  for (let n = 0; n < sampleCount; n++) {
    const i = indices[n];
    const j = i * 4;
    const confidence = maskArray[i];
    if (confidence > confidenceThreshold) {
      const r = originalImageData.data[j];
      const g = originalImageData.data[j + 1];
      const b = originalImageData.data[j + 2];
      localColors.push([r, g, b]);
    }
    sampled++;
    if (sampled % 100 === 0) {
      setAllExtractedColors([...localColors]);
    }
  }

  resolve();
});

          await processMask();
          console.log(`æŠ½å‡ºçµ‚äº† è‰²æ•°: ${localColors.length}`);
          onCaptureFinished();
          captureModeRef.current = false; // æŠ½å‡ºå®Œäº†å¾Œã«ã‚­ãƒ£ãƒ—ãƒãƒ£ãƒ¢ãƒ¼ãƒ‰ã‚’è§£é™¤
        } else {
          onCaptureFinished();
          captureModeRef.current = false;
        }
      } else {
        onCaptureFinished(); // No clothes detected
        captureModeRef.current = false;
      }
    } else if (!isCapturing && videoRef.current && !videoRef.current.ended) {
      // æŠ½å‡ºãƒ¢ãƒ¼ãƒ‰ãŒè§£é™¤ã•ã‚ŒãŸã‚‰å†é–‹
      captureModeRef.current = false;
      const video = videoRef.current;
      if (video.paused) {
        video.play().catch(e => console.error('Failed to resume video:', e));
      }
    } else {
      onCaptureFinished(); // æ¡ä»¶æœªæº€æ™‚
      captureModeRef.current = false;
    }
  };
  process();
}, [isCapturing, onProgress, setAllExtractedColors]);

    
  return null;
};


export default ImageSegmentClothes;